---
title: "GDP Prediction"
author: "Nikhil Gutpa and Stuart Miller"
date: "`r Sys.time()`"
output:
  github_document: 
    toc: yes
    toc_depth: 6
  word_document:
    toc: yes
    toc_depth: '6'
  html_document:
    toc: yes
    toc_depth: 6
    toc_float: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
library(tswge)
library(tswgewrapped)
library(tidyverse)
library(ggplot2)
library(tseries)
library(kableExtra)
library(knitr)
data <- read.csv("../data/economic_indicators_all_ex_3mo_china_inc_treas3mo.csv")[1:151, ]
data.train <- data[1:149, ]
data.test <- data[150:151, ]
```



# Introduction

Economic recessions are periods of time when an economy shinks.
These periods of time generally costly to businesses and the populace alike.
Deep recessions can be particularly costly to the populace as business downsizing and business failures during recessions generally result in a decrease in available jobs (increasing unemployment).
However, if it was possible to predict a coming recession with some confidence, then it may be possible for business and the populace to prepare and mitigate losses.

We propose to model the change in GDP for the United States to attempt to predict recessions.
A working definition of a recession is two consecutive quarters of decrease in GDP [1].
Thus, we will use a 2-step ahead forecast in evaluating models.
Eleven years (44 quarters) of historical data will be used for training models to predict the next 2 quarters.

# Data

All data was collected from [Federal Reserve Economic Data (FRED) Repository](https://fred.stlouisfed.org/),
which is provided by the Federal Reserve Bank of Saint Louis.
In addition to quarterly change in GDP, 18 exogenous variables were also collected.
The data from 151 quarters (from 1982 Q1 to 2019 Q3) were collected.
The data starts at 1982 Q1 because that was the earliest observation available for `treas10yr3mo`.

The exogenous variables are summerized in the table below.

| Variable | Description | FRED ID |
|----------|-------------|---------|
| Date     | Date of observation | N/A |
| gdp_change | Change in GDP from the previous observation | A191RP1Q027SBEA |
| unrate   | Unemployment rate | UNRATE |
| nfjobs   | Non-farming jobs  | PAYEMS | 
| treas10yr | 10 Year US treasury constant maturity rate | DGS10 |
| fedintrate | US federal interest rate | FEDFUNDS |
| personincomechg | Change in real disposable personal income | A067RO1Q156NBEA |
| cpichg | Change in Consumer Price Index for all urban consumers: all ttems in U.S. city average | CPIAUCNS |
| popchg | Change in Population | POPTHM |
| corpprofitchg | Change in Corporate profits after tax (converted to percent change) | CP |
| crude_wtichg | Change in Spot Crude Oil Price: West Texas Intermediate | WTISPLC |
| goldchg | Change in Gold Fixing Price 10:30 A.M. (London time) in london bullion market, based in U.S. Dollars | GOLDAMGBD228NLBM |
| ppichg | Change in Producer price index | PPIACO |
| japanchg | Change in US/Japan exchange rate | EXJPUS | 
| ukchg | Change in US/UK exchange rate | EXUSUK |
| wilshirechg | Change in Wilshire 5000 Total Market Full Cap Index | WILL5000INDFC |
| ipichg | Change in Industrial Production Index | INDPRO |
| inventorieschg | Change in Real Manufacturing and Trade Inventories | INVCMRMTSPL |
| homeownership | Cahnge in Homeownership Rate for the United States | RHORUSQ156N |
| housingpermitschg | Change in New Private Housing Units Authorized by Building Permits | PERMIT |
| treas10yr3mo | 10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity | T10Y3M |

```{r}
data %>% glimpse()
```

# Response Variable

The response variable is change in GDP, denoted as `gdp_change`.
The realization, sample autocorrelations, and Parzen window are shown below.
The realization appears to express wandering behavior with some oscillation.
Based on the sample aucorrelations, wandering appears to be the dominate behavior.
The oscillations do not appear to be expressed strongly in the sample autocorrelations.
This is consisent with the Parzen window, which shows a dominate frequency at 0.
The other frequencies shown in the parzen window have very low magnitudes.

```{r, echo=FALSE}
x = data$gdp_change
var_interest <- 'gdp_change'
px = plotts.sample.wge(x)
```

# Modeling

## Stationarity

We start the analysis with an assessment of startionarity of the realization.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
check_stationarity(x, ylab = 'Change in GDP', title = 'Realization of Change in GDP')
```

### Condition 1: Constant Mean

* There does not appear to be evidence of a trend in the data.
* Additionaly there does not appear to be any kind of deterministic oscillation in the data

Therefore, the assumption of constant mean does not appear to be violated.

### Condition 2: Constant Variance

* There does not apprear to be evidence of the variance of the realization changing over time.
* the drastic change at time step 75 maybe uncharacterisic of the process generating this realization, but it is difficult to determine with only one realization. This could be normal wandering behavior of the process generating this realization.

Therefore, the assumption of constant variance does not appear to be violated.

### Condition 3: Constant Autocorrelation

The ACF of the first and second half of the realization appear to exhibit similar behavior.
However, the autocorrelations have very low magnitudes - most of the autocorrelations do not appear to be significantly different than 0.

Therefore, the assumption of constant autocorrelation does not appear to be violated.

### Conclusion

Given the above analysis, there does not appear to be sufficient evidence to suggest that the process generating the realization is not stationary.
We will continue the ananlysis assuming the process generating the realization is stationary.

## ARMA Model

Since the process generating the realization is assumed to be stationary, we will model this realization with an ARMA model.

### Model ID

```{r, echo=FALSE}
# get the top five models selected by AIC and BIC
aicbic.tables <- aicbic(x, 0:12, 0:3, silent = TRUE)

# print the aic table
aicbic.tables[[1]] %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)

# print the bic table
aicbic.tables[[2]] %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Both AIC and BIC select low order models with an ARMA(2, 0) selected as the best ID by both criteria.
The following models are selected by both criteria:

* ARMA(2, 0)
* ARMA(1, 1)
* ARMA(1, 2)
* ARMA(2, 1)


### Model Fit

An ARMA(2,0) was fit based on the model ID from AIC and BIC.
The factor table for the estimated model does not show roots near the unit circle.

```{r}
est.s <- est.arma.wge(data.train$gdp_change, 2, 0)
```

(1-0.7391 $B$ )(1+0.3472 $B$ )( $X_{t}$ - `r mean(data$gdp_change)`) = $a_{t}$ with $\sigma_{a}^2$ = `r est.s$avar`


The results from the model fit appear to be nearly consisent with white noise.
The resulting realization appears very close to white noise.
Several of the autocorrelations of the results are marginally significant, but not more than expected.
As secondary evaluation, the Ljung-Box test does not reject the null hypothesis that residuals are not white noise.
However, all the models selected by AIC and BIC show a similar behavior.

```{r, message=FALSE, echo=FALSE}
# evaluate residuals of arma model
tbl <- tswgewrapped::evaluate_residuals(est.s$res)
tbl %>%
  select(-c(Model)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


### Forecast Results


```{r, results='hide'}
# setup object with unitvariate model
models = list("ARMA(2,0)" = list(phi = est.s$phi,
                                  theta = est.s$theta,
                                  vara = est.s$avar,
                                  res = est.s$res,
                                  sliding_ase = TRUE))

mdl_compare_uni = tswgewrapped::ModelCompareUnivariate$new(data = data.train$gdp_change, mdl_list = models,
                                                       n.ahead = 2, batch_size = 44)
```

The model appears to capture the movement of the mean with 2-step ahead forecasts.
The model is unable to capture the steap dip near time step 100.
Generally, the realization is contained in the forecast limits of the model, but the realization does not exhibit significant wandering.
The sliding window ASE shows that the model performs badly near the extreme step.

```{r, message=FALSE, warning=FALSE}
# show sliding window forecasts
tbl <- mdl_compare_uni$plot_batch_forecasts(only_sliding = TRUE)
```

The histogram of ASEs from the sliding window shows that the errors are generally below 10.
However, there are a few exteme values with one above 60.

```{r}
# show the distribution of ASEs
tbl <- mdl_compare_uni$plot_boxplot_ases()
```

Viewing the rolling window ASE over time, we see that the most extreme value occurs at the same location as the extreme value.
This is not surprising since an ARMA model will tend toward the mean and this value is far from the window mean.

```{r, message=FALSE, warning=FALSE}
# show ASE over time (windows)
tbl <- mdl_compare_uni$plot_batch_ases(only_sliding = TRUE)
```


## VAR Model

### Explanatory Variables

The realizations of the exogeneous variables are shown below.

The variables `fedintrate` and `treas3mo` appear to be collinear; we will keep `fedintrate`.

```{r, fig.width=15, fig.height=15}
eda <- MultivariateEDA$new(data = data, var_interest = "gdp_change", var_time = "date")
eda$plot_data(ncol = 3)
```



### CCF Analysis

**Summary**

The significant cross correlations of the variable `popchg` lags the response variable.
The following variables do no have significant cross correlations with the response variable:
`corpprofitchg`, `japanchg`, `japanchg`, `crude_wtchg`, `goldchg`, and `ukchg`.
All other variables appear to have significant cross correlations and will be included as exogeneous variables.

We suspect that `nfjobschg`, `ipichg`, `treas10yr`, `fedintrate`, `cpichg`, `inventorieschg`, `ppichg`, `homeownership`, `personincomechg`, `housingpermitschg`, `treas10yr3mo`, `wilshirechg`, `ipichg` will be useful given the cross-correlations.

Plots of the CCF are shown below.

```{r, message=FALSE}
# plot the ccfs and get back the ccf table
ccf <- eda$plot_ccf_analysis(negative_only = TRUE)
# show the ccf table
ccf %>%
  select(-c(max_ccf_index_adjusted)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


Subset to variables that may be useful given cross-correlations.

```{r}
# Subset data to most intersting variables
data.train <- data.train %>% dplyr::select(c(gdp_change, nfjobschg, ipichg, treas10yr,
                                 fedintrate, cpichg, inventorieschg, ppichg,
                                 homeownership, personincomechg, housingpermitschg,
                                 treas10yr3mo, wilshirechg, ipichg))
data.test <- data.test %>% dplyr::select(c(gdp_change, nfjobschg, ipichg, treas10yr,
                                 fedintrate, cpichg, inventorieschg, ppichg,
                                 homeownership, personincomechg, housingpermitschg,
                                 treas10yr3mo, wilshirechg, ipichg))
```




### Modeling

Initially we attempted to select models starting with all the variables and removing statistially insiginificant variables.
However, this resulted in models that appeared to be very overfit.
For more details see *VAR Modeling with Backward Feature Selection* in the appendix.

We continued by starting with no variables in the model and visualizing the forecast at each variable addition to determine if the model appeared to overfit.
This resulted in a much smaller model.
The constant term was found to be significant, but the trend term was not significant. 
Thus, we only fit models with the constant term.

The models selected contained the variables `housingpermitschg` and `inventorieschg`.

```{r, message=FALSE, results='hide', warning=FALSE}
# Use max lag of 12
lag.max = 12
# construct VAR model with type const and variables 'housingpermitschg', 'inventorieschg'
models = list("VARS AIC Both"    = list(select = "aic", trend_type = "const", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data.train[ , c(var_interest, 'housingpermitschg', 'inventorieschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)

#mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.both <- mdl_build$get_final_models(subset = 'r')

# construct VAR model with type const and variable 'inventorieschg'
models = list("VARS AIC Inven"    = list(select = "aic", trend_type = "const", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data.train[ , c(var_interest, 'inventorieschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)

#mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.inven <- mdl_build$get_final_models(subset = 'r')

# construct VAR model with type const and variable 'housingpermitschg'
models = list("VARS AIC HousePerm"    = list(select = "aic", trend_type = "const", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data.train[ , c(var_interest, 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)

#mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.housperm <- mdl_build$get_final_models(subset = 'r')

# combine models in a list
models <- append(model.both, model.inven)
models <- append(models, model.housperm)

# set models to use sliding window ASE
for (name in names(models)){
  models[[name]][['sliding_ase']] = TRUE
}

# set the batch size (window) and forecast horizon
batch_size = 44
n.ahead = 2

# run model comparison
mdl_compare_var = ModelCompareMultivariateVAR$new(data = data.train, var_interest = var_interest,
                                              mdl_list = models, n.ahead = n.ahead, batch_size = batch_size, verbose = 1)

```

```{r, warning=FALSE, message=FALSE}
# show forecasts on batches
tbl <- mdl_compare_var$plot_batch_forecasts()
# show distributions of ASEs
tbl <- mdl_compare_var$plot_boxplot_ases()
```


It is difficult to determine when models appear to perform well based on the plot of the rolling forecasts.
However, there appears to be some evidence that the forecast lags the behavior of the realization.
While there are several instances where this behvaior can be seen, it is particularly evident when the realization dips suddenly near time step 75.
The models forecast a dip in the next time step.

Like the univariate models, these VAR models appear generally tend to capture the movement of the realization within the forecast intervals.

From the plot of the rolling ASE, the model containing only `inventorieschg` appears to perform best.
The ASE appears to be lower on average over the windows with the spread of the main distribution also being lower than the other two models.
The outliers of the ASE plot also appear to be as extreme or less extreme than the other two models.
We will select the VAR model containing on `inventorieschg` as an explanatory variable.

```{r, warning=FALSE, message=FALSE}
mdl_compare_var$remove_models(c('VARS AIC Both - R', 'VARS AIC HousePerm - R'))
```

### Model Fit

An examination of the residuals show that the residuals of the VAR appear to be consistent with white noise.
The autocorrelations of the residuals also appear to be consistent with white noise.
A few autocorrelations are marginally significant, but this is with in the 95% confidence level.
Additionally, the Ljung-Box test fails to reject the null hypothesis that the realization is not white noise with K at 24 and 48.

```{r, echo=FALSE}
resids <- resid(models$`VARS AIC Inven - R`$varfit)
tbl <- tswgewrapped::evaluate_residuals(resids[ , 1])
tbl %>%
  select(-c(Model)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## Neural Network Model

### Hyperparameter Grid Search

All of the data is used in the neural network.
We ran the neural network with different sets of variables and the performance appeared to decrease when varaibles were removed - 
see *Neural Networks with Sets of Regressors* in the appedix for more details.
A grid search is performed over number of repetitions, the number of hidden layers, and whether seasonality is allowed.

```{r, echo=FALSE}
# variables were previously dropped for the VAR model; just bring them back
data <- read.csv("../data/economic_indicators_all_ex_3mo_china_inc_treas3mo.csv")
data <- data %>% select(-date)
data.train <- data[1:149, ]
data.test <- data[150:151, ]
```


```{r, results='hide', warning=FALSE}
# setup search grid
nnfor_grid = expand.grid(reps = c(15, 25, 35, 45),
                         hd = c(1:7),
                         allow.det.season = c(FALSE, TRUE))
# search for best NN hyperparameters in given grid
model = ModelBuildNNforCaret$new(data = data.train, var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 grid = nnfor_grid,
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

temp <- model$summarize_best_hyperparams()
res <- model$summarize_hyperparam_results()
final.ase <- filter(res, reps == temp$reps &
                      hd == temp$hd &
                      allow.det.season == temp$allow.det.season)[['ASE']]
```

The ASE associated with the grid of hyperparameters is shown in the heatmap below.
The panel (True/False) is for the seasonality option.
Seasonality does not appear to have an affect on ASE.
However, the combination of number of hidden layers and number of repetitions strongly affects the ASE.
The best hyperparameters based on this grid search are `r temp$reps` repetitions and `r temp$hd` hidden layers, 
 which has a mean rolling window ASE of `r final.ase`.

```{r}
model$plot_hyperparam_results()
```

The best hyperparemeters are shown below

```{r, echo=FALSE}
model$summarize_best_hyperparams() %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


```{r, results='hide', warning=FALSE}
# get back the final model

# setup search grid
nnfor_grid = expand.grid(reps = c(temp$reps),
                         hd = c(temp$hd),
                         allow.det.season = c(temp$allow.det.season))
# search for best NN hyperparameters in given grid
model = ModelBuildNNforCaret$new(data = data.train, var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 grid = nnfor_grid,
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

caret_model = model$get_final_models()
mdl_compare_nn = ModelCompareNNforCaret$new(data = data.train,
                                         var_interest = var_interest,
                                         mdl_list = caret_model,
                                         verbose = 1)
```

### Model Fit

A plot of the residuals shows that the residuals do not appear to be consistent with white noise.
This is also evident from the ACF, which has more significant autocorrelations than expected.
However, we will keep this model as it may still be useful as we are forecasting a short horizon.


```{r, echo=FALSE}
# get back the nnfor mlp model
model.nnfor <- model$get_final_models(subset = 'r')

# get the residuals 
values.fitted <- as.numeric(model.nnfor$fitted)
size <- length(data.train$gdp_change)
diff.size <- length(data.train$gdp_change) - length(values.fitted) + 1
resids <- values.fitted - data.train$gdp_change[diff.size : size]

tbl <- tswgewrapped::evaluate_residuals(resids)
tbl %>%
  select(-c(Model)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)

```


### Forecast Results

The rolling window forecasts for the neural network model is shown below.
In general, the forecasts do not appear to capture the variance of the realization.
In fact, the forecasts are in the opposite direction of the realization such as the instance near time step 75.
This model also appears to miss the dips near step 100.

```{r}
# plot the rolling window forecasts
p = mdl_compare_nn$plot_batch_forecasts()
```

The plot of ASE over time shows that the ASE appears to spike frequently, especially near sharp changes in the realization.

```{r, warning=FALSE}
# plot the ASC over time
p = mdl_compare_nn$plot_batch_ases() 
```

## Comparison of Base Models

The rolling window ASE distributions for each type of model constructed are shown below.
Overall, the ARMA(2, 0) model produces forecasts with the least error as the mean and upper IQR line appear to have a lower value than the other two models.
Each model has a window forecast ASE above a value of 60. 
These are the forests for the steap dip in the realization after time step 100, indicating that none of the models are forecasting this change.

```{r}
newxreg <- data.test %>% dplyr::select(-!!var_interest)

# build compare model object
mdl_combine = ModelCombine$new(data = data.train, 
                               var_interest = var_interest,
                               uni_models = mdl_compare_uni, 
                               var_models = mdl_compare_var, 
                               mlp_models = mdl_compare_nn,
                               verbose = 1)
# plot the distributions of ASE from the rolling windows
mdl_combine$plot_boxplot_ases()
```

Comparing the rolling window forecasts of each model, we can make several observations.
The ARMA model appears to be conservative, but generally captures the movement of the realization.
The VAR model captures the movement of the realization, but wanders away from the realization in some cases.
The neural network model does not capture the movement of the realization as well as the ARMA model or the VAR model.
This is particularly evident in the second half of the forecasts where the neural network appears to have a high variance.
Additionally, all models appear to lag the major dip in the realization after time step 100.

```{r}
mdl_combine$plot_batch_forecasts()
```



## Ensemble Model

```{r}
mdl_combine$create_ensemble()
```

```{r}
mdl_combine$get_tabular_metrics(ases = FALSE) %>% na.omit()
mdl_combine$statistical_compare()
```

```{r}
#mdl_combine$predict_ensemble(naive = TRUE, newxreg = newxreg)
```


## Conclusion

# References

 1. Jim Chappelow, Recession,  Investopedia. Accessed March 6, 2020. https://www.investopedia.com/terms/r/recession.asp
 2. U.S. Bureau of Economic Analysis, Gross Domestic Product [A191RP1Q027SBEA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/A191RP1Q027SBEA, March 6, 2020.
 3. U.S. Bureau of Labor Statistics, All Employees, Total Nonfarm [PAYEMS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PAYEMS, March 6, 2020.
 4. Board of Governors of the Federal Reserve System (US), 10-Year Treasury Constant Maturity Rate [DGS10], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/DGS10, March 6, 2020.
 5. Board of Governors of the Federal Reserve System (US), Effective Federal Funds Rate [FEDFUNDS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/FEDFUNDS, March 6, 2020.
 6. U.S. Bureau of Economic Analysis, Real Disposable Personal Income [A067RO1Q156NBEA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/A067RO1Q156NBEA, March 6, 2020.
 7. U.S. Bureau of Labor Statistics, Consumer Price Index for All Urban Consumers: All Items in U.S. City Average [CPIAUCNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CPIAUCNS, March 6, 2020.
 8. U.S. Bureau of Economic Analysis, Population [POPTHM], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/POPTHM, March 6, 2020.
 9. U.S. Bureau of Economic Analysis, Corporate Profits After Tax (without IVA and CCAdj) [CP], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CP, March 6, 2020.
 10. Federal Reserve Bank of St. Louis, Spot Crude Oil Price: West Texas Intermediate (WTI) [WTISPLC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/WTISPLC, March 6, 2020.
 11. ICE Benchmark Administration Limited (IBA), Gold Fixing Price 10:30 A.M. (London time) in London Bullion Market, based in U.S. Dollars [GOLDAMGBD228NLBM], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/GOLDAMGBD228NLBM, March 6, 2020.
 12. Board of Governors of the Federal Reserve System (US), Japan / U.S. Foreign Exchange Rate [EXJPUS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/EXJPUS, March 6, 2020.
 13. Board of Governors of the Federal Reserve System (US), U.S. / U.K. Foreign Exchange Rate [EXUSUK], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/EXUSUK, March 6, 2020.
 14. Wilshire Associates, Wilshire 5000 Total Market Full Cap Index [WILL5000INDFC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/WILL5000INDFC, March 26, 2020.
 15. Federal Reserve Bank of St. Louis, Real Manufacturing and Trade Inventories [INVCMRMTSPL], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/INVCMRMTSPL, March 26, 2020.
 16. U.S. Census Bureau and U.S. Department of Housing and Urban Development, New Private Housing Units Authorized by Building Permits [PERMIT], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PERMIT, March 26, 2020.
 17. U.S. Census Bureau, Homeownership Rate for the United States [RHORUSQ156N], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/RHORUSQ156N, March 26, 2020.
 18. Board of Governors of the Federal Reserve System (US), Industrial Production Index [INDPRO], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/INDPRO, March 26, 2020.
 19. Federal Reserve Bank of St. Louis, 10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity [T10Y3M], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/T10Y3M, March 26, 2020.

# Appendix

## VAR Modeling with Backward Feature Selection

### VAR with `trend_type = Trend`

**Iteration 1**

Starting with all variables with non-zero cross-correlation and max lag of 12.

```{r}
data = read.csv("../data/economic_indicators_all_ex_3mo_china.csv")[80:195, ]
data <- data %>% dplyr::select(c(gdp_change, nfjobschg, ipichg, treas10yr,
                                 fedintrate, cpichg, inventorieschg, ppichg, popchg,
                                 homeownership, corpprofitchg, personincomechg, housingpermitschg,
                                 japanchg))

lag.max = 12
models = list("VARS AIC Trend"    = list(select = "aic", trend_type = "trend", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data, var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

The recommended model as a lag of 7 and most variables are not significant in the model.
Additionally, trend is not significant in the model.

**Iteration 2**

Variable `japanchg` is removed and max lags remains at 12.


```{r}
lag.max = 12
models = list("VARS AIC Trend"    = list(select = "aic", trend_type = "trend", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

All varaibles are now significant in the model.
Trend is still not significant at the 0.05 level, but it is marginal.

**Iteration 3**

The max lag to test is reduced to 7.

```{r}
lag.max = 7
models = list("VARS AIC Trend"    = list(select = "aic", trend_type = "trend", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.trend <- mdl_build$get_final_models(subset = 'r')
```

The recommended model remains the same as the previous model.

### VAR with `trend_type = Both`

**Iteration 1**

Starting with all variables with non-zero cross-correlation and max lag of 12.

```{r}
lag.max = 12
models = list("VARS AIC Both"    = list(select = "aic", trend_type = "both", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data,
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

The recommended model as a lag of 7 and most variables are not significant in the model.
Additionally, trend and const are not significant in the model.

**Iteration 2**

Variable `japanchg` is removed and max lags remains at 12.


```{r}
lag.max = 12
models = list("VARS AIC Both"    = list(select = "aic", trend_type = "both", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

All varaibles are now significant in the model.
Trend and const are not significant in the model

**Iteration 3**

The max lag to test is reduced to 7.

```{r}
lag.max = 7
models = list("VARS AIC Both"    = list(select = "aic", trend_type = "both", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.both <- mdl_build$get_final_models(subset = 'r')
```

The recommend model is the same as the previous model.

### VAR with `trend_type = Const`

**Iteration 1**

Starting with all variables with non-zero cross-correlation and max lag of 12.

```{r}
lag.max = 12
models = list("VARS AIC Const"    = list(select = "aic", trend_type = "const", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data,
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

The recommended model as a lag of 7 and most variables are not significant in the model.
Additionally, const is not significant in the model.

**Iteration 2**

Variable `japanchg` is removed and max lags remains at 12.


```{r}
lag.max = 12
models = list("VARS AIC Const"    = list(select = "aic", trend_type = "both", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

All varaibles are now significant in the model.
Const is not significant in the model

**Iteration 3**

The max lag to test is reduced to 7.

```{r}
lag.max = 7
models = list("VARS AIC Const"    = list(select = "aic", trend_type = "both", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.const <- mdl_build$get_final_models(subset = 'r')
```

The recommend model is the same as the previous model.

### VAR with `trend_type = None`



```{r}
lag.max = 12
models = list("VARS AIC None"    = list(select = "aic", trend_type = "none", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data = data,
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```


```{r}
lag.max = 12
models = list("VARS AIC None"    = list(select = "aic", trend_type = "none", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
```

```{r}
lag.max = 7
models = list("VARS AIC None"    = list(select = "aic", trend_type = "none", lag.max = lag.max))
mdl_build = ModelBuildMultivariateVAR$new(data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')],
                                          var_interest = var_interest,
                                            mdl_list = models, verbose = 1)
mdl_build$summarize_build()
mdl_build$build_recommended_models()
model.none <- mdl_build$get_final_models(subset = 'r')
```

The recommended model is the same as the previous model.

### Compare Models

Three models show much higher error than the model with trend type of none.
However, this model still has very large errors compared to the univariate models.

```{r}
models <- append(model.both, model.const)
models <- append(models, model.none)
models <- append(models, model.trend)
for (name in names(models)){
  models[[name]][['sliding_ase']] = TRUE
}
batch_size = 44
n.ahead = 2
mdl_compare = ModelCompareMultivariateVAR$new(data = data, var_interest = var_interest,
                                              mdl_list = models, n.ahead = n.ahead, batch_size = batch_size, verbose = 1)
mdl_compare$plot_batch_forecasts()
mdl_compare$plot_boxplot_ases()
```

Rerun the comparison with the noisy models removed.

```{r}
mdl_compare$remove_models(c("VARS AIC Const - R",
                            "VARS AIC Both - R",
                            "VARS AIC Trend - R"))
mdl_compare$plot_batch_forecasts()
mdl_compare$plot_boxplot_ases()
```

## Neural Networks with Sets of Regressors

It is difficult to determine which exogeneous variables should be included in the model.
We will see the impact by just random removing variables until no variables are left.
Remove a random variable until only one variable is left in the model.

**Results Summary**

Essential the ASE appears to increase when variables are removed from the model.
Based on this, we will fit the neural network with all the variables in the model.

## Iteration 1

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg', 'housingpermitschg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 2

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg', 'personincomechg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 3

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'corpprofitchg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```


## Iteration 5


```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership', 'personincomechg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 5

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg',
                                                           'homeownership')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 6

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'fedintrate', 'cpichg', 'inventorieschg', 'ppichg', 'popchg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 7

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'nfjobschg', 'ipichg', 'treas10yr',
                                                           'cpichg', 'inventorieschg', 'ppichg', 'popchg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 8

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'ipichg', 'treas10yr',
                                                           'cpichg', 'inventorieschg', 'ppichg', 'popchg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 9

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'ipichg', 'treas10yr',
                                                           'cpichg', 'inventorieschg', 'popchg')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```

## Iteration 10

```{r}

model = ModelBuildNNforCaret$new(data = data[ , c(var_interest, 'homeownership')], 
                                 var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

model$summarize_hyperparam_results()
model$plot_hyperparam_results()
```





