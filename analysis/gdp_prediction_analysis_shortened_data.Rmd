---
title: "GDP Prediction"
author: "Nikhil Gutpa and Stuart Miller"
date: "`r Sys.time()`"
output:
  github_document: 
    toc: yes
    toc_depth: 6
  word_document:
    toc: yes
    toc_depth: '6'
  html_document:
    toc: yes
    toc_depth: 6
    toc_float: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE}
# load libraries
library(tswge)
library(tswgewrapped)
library(tidyverse)
library(ggplot2)
library(tseries)
library(kableExtra)
library(knitr)
# read data set
data <- read.csv("../data/economic_indicators_all_ex_3mo_china_inc_treas3mo.csv")
# split data into a train and test set
data_train = data %>% dplyr::slice(1:(dplyr::n()-n.ahead))
data_test = data %>% dplyr::slice((dplyr::n()-n.ahead), dplyr::n())
# global settings
var_interest = 'gdp_change'
batch_size = 50
n.ahead = 2
```

# Introduction

Economic recessions are periods of time when an economy shinks.
These periods of time generally costly to businesses and the populace alike.
Deep recessions can be particularly costly to the populace as business downsizing and business failures during recessions generally result in a decrease in available jobs (increasing unemployment).
However, if it was possible to predict a coming recession with some confidence, then it may be possible for business and the populace to prepare and mitigate losses.

We propose to model the change in GDP for the United States to attempt to predict recessions.
A working definition of a recession is two consecutive quarters of decrease in GDP [1].
Thus, we will use a 2-step ahead forecast in evaluating models.
50 quarters of historical data will be used for training models to predict the next 2 quarters.

# Data

All data was collected from [Federal Reserve Economic Data (FRED) Repository](https://fred.stlouisfed.org/),
which is provided by the Federal Reserve Bank of Saint Louis.
In addition to quarterly change in GDP, 18 exogenous variables were also collected.
The data from 151 quarters (from 1982 Q1 to 2019 Q3) were collected.
The data starts at 1982 Q1 because that was the earliest observation available for `treas10yr3mo`.

The exogenous variables are summerized in the table below.

| Variable | Description | FRED ID |
|----------|-------------|---------|
| Date     | Date of observation | N/A |
| gdp_change | Change in GDP from the previous observation | A191RP1Q027SBEA |
| unrate   | Unemployment rate | UNRATE |
| nfjobs   | Non-farming jobs  | PAYEMS | 
| treas10yr | 10 Year US treasury constant maturity rate | DGS10 |
| fedintrate | US federal interest rate | FEDFUNDS |
| personincomechg | Change in real disposable personal income | A067RO1Q156NBEA |
| cpichg | Change in Consumer Price Index for all urban consumers: all ttems in U.S. city average | CPIAUCNS |
| popchg | Change in Population | POPTHM |
| corpprofitchg | Change in Corporate profits after tax (converted to percent change) | CP |
| crude_wtichg | Change in Spot Crude Oil Price: West Texas Intermediate | WTISPLC |
| goldchg | Change in Gold Fixing Price 10:30 A.M. (London time) in london bullion market, based in U.S. Dollars | GOLDAMGBD228NLBM |
| ppichg | Change in Producer price index | PPIACO |
| japanchg | Change in US/Japan exchange rate | EXJPUS | 
| ukchg | Change in US/UK exchange rate | EXUSUK |
| wilshirechg | Change in Wilshire 5000 Total Market Full Cap Index | WILL5000INDFC |
| ipichg | Change in Industrial Production Index | INDPRO |
| inventorieschg | Change in Real Manufacturing and Trade Inventories | INVCMRMTSPL |
| homeownership | Cahnge in Homeownership Rate for the United States | RHORUSQ156N |
| housingpermitschg | Change in New Private Housing Units Authorized by Building Permits | PERMIT |
| treas10yr3mo | 10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity | T10Y3M |

```{r}
data %>% glimpse()
```

# Response Variable

The response variable is change in GDP, denoted as `gdp_change`.
The realization, sample autocorrelations, and Parzen window are shown below.
The realization appears to express wandering behavior with some oscillation.
Based on the sample aucorrelations, wandering appears to be the dominate behavior.
The oscillations do not appear to be expressed strongly in the sample autocorrelations.
This is consisent with the Parzen window, which shows a dominate frequency at 0.
The other frequencies shown in the parzen window have very low magnitudes.

```{r, echo=FALSE}
px = plotts.sample.wge(data_train$gdp_change)
```

# Modeling

## Stationarity

We start the analysis with an assessment of startionarity of the realization.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
check_stationarity(data_train$gdp_change, ylab = 'Change in GDP', title = 'Realization of Change in GDP')
```

### Condition 1: Constant Mean

* There does not appear to be evidence of a trend in the data.
* Additionaly there does not appear to be any kind of deterministic oscillation in the data

Therefore, the assumption of constant mean does not appear to be violated.

### Condition 2: Constant Variance

* There does not apprear to be evidence of the variance of the realization changing over time.
* the drastic change at time step 75 maybe uncharacterisic of the process generating this realization, but it is difficult to determine with only one realization. This could be normal wandering behavior of the process generating this realization.

Therefore, the assumption of constant variance does not appear to be violated.

### Condition 3: Constant Autocorrelation

The ACF of the first and second half of the realization appear to exhibit similar behavior.
However, the autocorrelations have very low magnitudes - most of the autocorrelations do not appear to be significantly different than 0.

Therefore, the assumption of constant autocorrelation does not appear to be violated.

### Conclusion

Given the above analysis, there does not appear to be sufficient evidence to suggest that the process generating the realization is not stationary.
We will continue the ananlysis assuming the process generating the realization is stationary.

## ARMA Model

Since the process generating the realization is assumed to be stationary, we will model this realization with an ARMA model.

### Model ID

```{r, warning=FALSE}
# get the top five models selected by AIC and BIC
aicbic.tables <- aicbic(data_train$gdp_change, 0:12, 0:3, silent = TRUE)
```


```{r, echo=FALSE}
# print the aic table
aicbic.tables[[1]] %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)

# print the bic table
aicbic.tables[[2]] %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

Both AIC and BIC select low order models with an ARMA(2, 0) selected as the best ID by both criteria.
The following models are selected by both criteria:

* ARMA(2, 0)
* ARMA(1, 1)
* ARMA(1, 2)
* ARMA(2, 1)


### Model Fit

An ARMA(2,0) was fit based on the model ID from AIC and BIC.
The factor table for the estimated model does not show roots near the unit circle.

```{r}
est.s <- est.arma.wge(data_train$gdp_change, 2, 0)
```

The following factored model is suggested by the MLE fit:

(1-0.7391 $B$ )(1+0.3472 $B$ )( $X_{t}$ - `r mean(data$gdp_change)`) = $a_{t}$ with $\sigma_{a}^2$ = `r est.s$avar`

#### Evaluation of the Residuals

The results from the model fit appear to be nearly consisent with white noise.
The resulting realization appears very close to white noise.
Several of the autocorrelations of the results are marginally significant, but not more than expected.
As secondary evaluation, the Ljung-Box test does not reject the null hypothesis that residuals are not white noise.
However, all the models selected by AIC and BIC show a similar behavior.

```{r, message=FALSE, echo=FALSE}
# evaluate residuals of arma model
tbl <- tswgewrapped::evaluate_residuals(est.s$res)
tbl %>%
  select(-c(Model)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

#### Model Characterisics

Realizations were simulated from the fit model for comparing realizations, ACFs, and spectral densities to the data.

* The realization simulated from the univariate model appear to have a similar amount of wandering and sharp changes.
* The ACFs of the simulated realizations appear to exhibit similar behavior through lag 7. After lag 7, one of the ACFs diverge from the other realizations. At lag 12 all of the ACFs start diverge.
* The spectral densitied generally show similar behavior: a peak at or near a frequency of zero with roll-off that ends at about frequency 0.15. One spectral density shows a peak slightly above 0 (about 0.03) with a steaper roll off. However, this spectral density is still exhibiting the general behavior.

```{r}
mdl_compare_uni$plot_multiple_realizations()
```



### Forecast Results


```{r, results='hide'}
# setup object with unitvariate model
models = list("AR(2)" = list(phi = est.s$phi, theta = est.s$theta, vara = est.s$avar,
                             res = est.s$res, sliding_ase = TRUE))

mdl_compare_uni = tswgewrapped::ModelCompareUnivariate$new(data = data_train$gdp_change, mdl_list = models,
                                                           n.ahead = n.ahead, batch_size = batch_size)
```

The model appears to capture the movement of the mean with 2-step ahead forecasts.
The model is unable to capture the steap dip near time step 100.
Generally, the realization is contained in the forecast limits of the model, but the realization does not exhibit significant wandering.
The sliding window ASE shows that the model performs badly near the extreme step.

```{r, message=FALSE, warning=FALSE}
# show sliding window forecasts
tbl <- mdl_compare_uni$plot_batch_forecasts(only_sliding = TRUE)
```

Viewing the rolling window ASE over time, we see that the most extreme value occurs at the same location as the extreme value.
This is not surprising since an ARMA model will tend toward the mean and this value is far from the window mean.

```{r, message=FALSE, warning=FALSE}
# show ASE over time (windows)
tbl <- mdl_compare_uni$plot_batch_ases(only_sliding = TRUE)
```


## VAR Model

### Explanatory Variables

The realizations of the exogeneous variables are shown below.

The variables `fedintrate` and `treas3mo` appear to be collinear; we will keep `fedintrate`.

```{r, fig.width=15, fig.height=15}
eda <- MultivariateEDA$new(data = data_train, var_interest = var_interest)
eda$plot_data(ncol = 3)
```



### CCF Analysis

**Summary**

We suspect that `nfjobschg`, `ipichg`, `treas10yr`, `fedintrate`, `cpichg`, `inventorieschg`, `ppichg`, `homeownership`, `personincomechg`, `housingpermitschg`, `treas10yr3mo`, `wilshirechg`, `ipichg` will be useful given the cross-correlations.

```{r, message=FALSE}
# plot the ccfs and get back the ccf table
ccf <- eda$plot_ccf_analysis(negative_only = TRUE)
# show the ccf table
ccf %>%
  slice(1:5) %>%
  select(-c(max_ccf_index_adjusted)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


### Modeling

The VAR models selected by the following process.

* AIC was used to select the maximum lag to consider.
* The model of the selected lag was fit.
* Variables insignificant in the fit are dropped and the maximum lag was reduced to the maximum significant lag found in the fit.


```{r, message=FALSE, warning=FALSE}
# maximum lag to consider in VAR models
lag.max = 10

# List of VAR models to build for comparison
models = list("VAR AIC None" = list(select = "aic", trend_type = "none", lag.max = lag.max),
              "VAR AIC Trend" = list(select = "aic", trend_type = "trend", lag.max = lag.max),
              "VAR AIC Both" = list(select = "aic", trend_type = "both", lag.max = lag.max))

# instantiate the model build object
mdl_build_var = ModelBuildMultivariateVAR$new(data = data_train, var_interest = var_interest,
                                              mdl_list = models, verbose = 0)
# summerize the the recommended models
mdl_build_var$summarize_build()
# get the recommended models
mdl_build_var$get_recommendations()
# build the VAR models
mdl_build_var$build_recommended_models()
# return the VAR models for comparison
models = mdl_build_var$get_final_models(subset = 'r')

# Setup Models to be compared with sliding ASE = TRUE
for (name in names(models)){
  models[[name]][['sliding_ase']] = TRUE
}

# Initialize the ModelCompareMultivariateVAR object
mdl_compare_var = ModelCompareMultivariateVAR$new(data = data_train, var_interest = var_interest,
                                                  mdl_list = models, n.ahead = n.ahead, batch_size = batch_size, verbose = 1)
```

The rolling window forecasts are shown below.
The model with trend and the model without trend and constant terms, appear to overshoot the movement of the realization.
This is especially true just after the large dip in the realization after time step 100.

```{r, warning=FALSE, message=FALSE}
# show forecasts on batches
tbl <- mdl_compare_var$plot_batch_forecasts()
```

Overall, the model with both trend and constant appears produce forecasts with lower ASEs on average.

```{r}
# show distributions of ASEs
tbl <- mdl_compare_var$plot_boxplot_ases()
```

Visualizing the realizations over time shows that the model with both trend and constant appears to perform best.
The large ASEs from the forecasts occur around the sharp dip in the realization just after time step 100.

```{r}
# 
p = mdl_compare_var$plot_batch_ases()
```

The model with both trend and constant terms appears to best.
We will drop the other two models from further analysis.

```{r, warning=FALSE, message=FALSE}
mdl_compare_var$keep_models(mdl_names = c("VAR AIC Both - R"))
```

### Model Fit

An examination of the residuals show that the residuals of the VAR appear to be consistent with white noise.
The autocorrelations of the residuals appear to be marginally inconsistent with white noise.
Since these residuals are close to white noise, we will assume the model is sufficient for modeling these data.

```{r, echo=FALSE}
resids <- resid(models$`VAR AIC Both - R`$varfit)
tbl <- tswgewrapped::evaluate_residuals(resids[ , 1])
```


## Neural Network Model

### Hyperparameter Grid Search

A grid search is performed over number of repetitions, the number of hidden layers, and whether seasonality is allowed.


```{r, results='hide', warning=FALSE}
# setup search grid
nnfor_grid = expand.grid(reps = c(15, 20, 25),
                         hd = c(1:5),
                         allow.det.season = c(FALSE, TRUE))
# search for best NN hyperparameters in given grid
model = ModelBuildNNforCaret$new(data = data_train, var_interest = var_interest,
                                 search = 'grid', grid = nnfor_grid, batch_size = batch_size,
                                 h = n.ahead, parallel = TRUE, seed = 1,
                                 verbose = 1)

temp <- model$summarize_best_hyperparams()
res <- model$summarize_hyperparam_results()
final.ase <- filter(res, reps == temp$reps &
                      hd == temp$hd &
                      allow.det.season == temp$allow.det.season)[['ASE']]
```

The ASE associated with the grid of hyperparameters is shown in the heatmap below.
The panel (True/False) is for the seasonality option.
Seasonality does not appear to have an affect on ASE.
However, the combination of number of hidden layers and number of repetitions strongly affects the ASE.
The best hyperparameters based on this grid search are `r temp$reps` repetitions and `r temp$hd` hidden layers, 
 which has a mean rolling window ASE of `r final.ase`.

```{r}
model$plot_hyperparam_results()
```

The best hyperparemeters are shown below

```{r}
tbl <- model$summarize_best_hyperparams() 
```


```{r, echo=FALSE}
tbl %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


```{r, results='hide', warning=FALSE}
# get back the final model

# setup search grid
nnfor_grid = expand.grid(reps = c(temp$reps),
                         hd = c(temp$hd),
                         allow.det.season = c(temp$allow.det.season))
# search for best NN hyperparameters in given grid
model = ModelBuildNNforCaret$new(data = data.train, var_interest = "gdp_change", m = 6,
                                 search = 'grid',
                                 grid = nnfor_grid,
                                 batch_size = 44, h = 2,
                                 parallel = TRUE,
                                 seed = 1,
                                 verbose = 1)

caret_model = model$get_final_models()
mdl_compare_nn = ModelCompareNNforCaret$new(data = data.train,
                                         var_interest = var_interest,
                                         mdl_list = caret_model,
                                         verbose = 1)
```

### Model Fit

A plot of the residuals shows that the residuals do not appear to be consistent with white noise.
This is also evident from the ACF, which has more significant autocorrelations than expected.
However, we will keep this model as it may still be useful as we are forecasting a short horizon.


```{r}
# get back the nnfor mlp model
model.nnfor <- model$get_final_models(subset = 'r')

# extract the fitted values for white noise evaluation
values.fitted <- as.numeric(model.nnfor$fitted)
# find the difference in length between the realization and the fitted values
size <- length(data.train$gdp_change)
diff.size <- length(data.train$gdp_change) - length(values.fitted) + 1
# get the residuals (fitted - realization)
resids <- values.fitted - data.train$gdp_change[diff.size : size]

tbl <- tswgewrapped::evaluate_residuals(resids)
tbl %>%
  select(-c(Model)) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F)

```


### Forecast Results

The rolling window forecasts for the neural network model is shown below.
In general, the forecasts do not appear to capture the variance of the realization.
In fact, the forecasts are in the opposite direction of the realization such as the instance near time step 75.
This model also appears to miss the dips near step 100.

```{r}
# plot the rolling window forecasts
p = mdl_compare_nn$plot_batch_forecasts()
```

The plot of ASE over time shows that the ASE appears to spike frequently, especially near sharp changes in the realization.

```{r, warning=FALSE}
# plot the ASC over time
p = mdl_compare_nn$plot_batch_ases() 
```

## Comparison of Base Models

The rolling window ASE distributions for each type of model constructed are shown below.
Overall, the ARMA(2, 0) model produces forecasts with the least error as the mean and upper IQR line appear to have a lower value than the other two models.
Each model has a window forecast ASE above a value of 60. 
These are the forests for the steap dip in the realization after time step 100, indicating that none of the models are forecasting this change.

```{r}
newxreg <- data_test %>% dplyr::select(-!!var_interest)

# build compare model object
mdl_combine = ModelCombine$new(data = data_train, 
                               var_interest = var_interest,
                               uni_models = mdl_compare_uni, 
                               var_models = mdl_compare_var, 
                               mlp_models = mdl_compare_nn,
                               verbose = 1)
# plot the distributions of ASE from the rolling windows
mdl_combine$plot_boxplot_ases()
```

Comparing the rolling window forecasts of each model, we can make several observations.
The ARMA model appears to be conservative, but generally captures the movement of the realization.
The VAR model captures the movement of the realization, but wanders away from the realization in some cases.
The neural network model does not capture the movement of the realization as well as the ARMA model or the VAR model.
This is particularly evident in the second half of the forecasts where the neural network appears to have a high variance.
Additionally, all models appear to lag the major dip in the realization after time step 100.

```{r}
mdl_combine$plot_batch_forecasts()
```



## Ensemble Models

Ensembles of the base models are created by combining the forecasts of the base models by selecting the mean forecasted value, selecting the median forecasted value, and building a linear regression model.
The assumptions for linear regression appear to be reazonably met based on the residual plots shown below.

```{r}
mdl_combine$create_ensemble()
```

```{r}

```

```{r}
#mdl_combine$predict_ensemble(naive = TRUE, newxreg = newxreg)
```


## Conclusion

# References

 1. Jim Chappelow, Recession,  Investopedia. Accessed March 6, 2020. https://www.investopedia.com/terms/r/recession.asp
 2. U.S. Bureau of Economic Analysis, Gross Domestic Product [A191RP1Q027SBEA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/A191RP1Q027SBEA, March 6, 2020.
 3. U.S. Bureau of Labor Statistics, All Employees, Total Nonfarm [PAYEMS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PAYEMS, March 6, 2020.
 4. Board of Governors of the Federal Reserve System (US), 10-Year Treasury Constant Maturity Rate [DGS10], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/DGS10, March 6, 2020.
 5. Board of Governors of the Federal Reserve System (US), Effective Federal Funds Rate [FEDFUNDS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/FEDFUNDS, March 6, 2020.
 6. U.S. Bureau of Economic Analysis, Real Disposable Personal Income [A067RO1Q156NBEA], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/A067RO1Q156NBEA, March 6, 2020.
 7. U.S. Bureau of Labor Statistics, Consumer Price Index for All Urban Consumers: All Items in U.S. City Average [CPIAUCNS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CPIAUCNS, March 6, 2020.
 8. U.S. Bureau of Economic Analysis, Population [POPTHM], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/POPTHM, March 6, 2020.
 9. U.S. Bureau of Economic Analysis, Corporate Profits After Tax (without IVA and CCAdj) [CP], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/CP, March 6, 2020.
 10. Federal Reserve Bank of St. Louis, Spot Crude Oil Price: West Texas Intermediate (WTI) [WTISPLC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/WTISPLC, March 6, 2020.
 11. ICE Benchmark Administration Limited (IBA), Gold Fixing Price 10:30 A.M. (London time) in London Bullion Market, based in U.S. Dollars [GOLDAMGBD228NLBM], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/GOLDAMGBD228NLBM, March 6, 2020.
 12. Board of Governors of the Federal Reserve System (US), Japan / U.S. Foreign Exchange Rate [EXJPUS], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/EXJPUS, March 6, 2020.
 13. Board of Governors of the Federal Reserve System (US), U.S. / U.K. Foreign Exchange Rate [EXUSUK], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/EXUSUK, March 6, 2020.
 14. Wilshire Associates, Wilshire 5000 Total Market Full Cap Index [WILL5000INDFC], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/WILL5000INDFC, March 26, 2020.
 15. Federal Reserve Bank of St. Louis, Real Manufacturing and Trade Inventories [INVCMRMTSPL], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/INVCMRMTSPL, March 26, 2020.
 16. U.S. Census Bureau and U.S. Department of Housing and Urban Development, New Private Housing Units Authorized by Building Permits [PERMIT], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/PERMIT, March 26, 2020.
 17. U.S. Census Bureau, Homeownership Rate for the United States [RHORUSQ156N], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/RHORUSQ156N, March 26, 2020.
 18. Board of Governors of the Federal Reserve System (US), Industrial Production Index [INDPRO], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/INDPRO, March 26, 2020.
 19. Federal Reserve Bank of St. Louis, 10-Year Treasury Constant Maturity Minus 3-Month Treasury Constant Maturity [T10Y3M], retrieved from FRED, Federal Reserve Bank of St. Louis; https://fred.stlouisfed.org/series/T10Y3M, March 26, 2020.

